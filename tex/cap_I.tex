\chapter{Introdução}
\label{cap:intro}
\section{Problema}

Visamos através deste trabalho demonstrar uma dentre várias maneiras para a realização de junção por similaridade de dados. Estas operações de junções por similaridade são essenciais na análise de Big Data \cite{Rong:2017:FS-Join}.

Para a análise de dados provenientes de \textit{Big Data}, a limpeza dos mesmos torna-se uma etapa essencial no processo de preenchimento e manutenção de \textit{Data Warehouses} e repositórios de dados centralizados. Assim sendo, uma das operação de limpeza muito importante é a de agrupar os dados semelhantes com a finalidade de evitar redundâncias nos dados armazenados, e neste processo de juntar é utilizado a operação de junção por similaridade\cite{Chaudhuri:2006:POS:1129754.1129865}.

Faz-se citar o fato de que uma das definições mais aceitas para o termo \textit{Big Data}, é o fato do significar dados muito grandes, muito rápidos ou muito difíceis para que ferramentas existentes possam processar-los\cite{Madden:2012}.

Diante dos fatos acima citados, nosso problema passa pela necessidade de realizar uma junção por similaridade de dados, em dados provenientes de \textit{Big Data}, com a finalidade de realizar a devida higienização dos dados obtidos utilizando da melhor forma possível os recursos computacionais disponíveis.

\section{Objetivo}

Este trabalho objetiva-se em avaliar o \textit{framework} \textit{FS-Join} proposto por \cite{Rong:2017:FS-Join}, utilizando para tal o arcabouço de processamentos distribuídos do \textit{Spark Apache}, e com apoio de implementação da linguagem Scala trabalhando sobre a JVM (\textit{Java Virtual Machine}). 

Utilizando assim o \textit{FS-Join} em parte de dados de \textit{Big Data} e medir sua eficácia em realizar a junção por similaridade dos dados, em relação a tempo de processamento e corretude nos resultados obtidos.

\section{Metodologia de pesquisa}

\section{Estrutura do trabalho}

