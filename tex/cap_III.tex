\chapter{Trabalhos relacionados}
\label{cap:trab_rel}

Existem muitos estudos sobre algoritmos de junção de similaridade de \textit{strings} em memória \cite{Gravano:2001:ASJ:645927.672200}, \cite{Sarawagi:2004:ESJ:1007568.1007652},\cite{Chaudhuri:2006:POS:1129754.1129865}, \cite{Arasu:2006:EES:1182635.1164206}, \cite{Bayardo:2007:SUP:1242572.1242591}, \cite{Xiao:2008:ESJ:1367497.1367516}, que podem ser categorizados em dois tipos: junção por similaridade de sequência baseada em conjunto (\textit{SSJoin}) e junção por similaridade de sequência baseada em caracteres (\textit{EDJoin}).  O \textit{SSJoin} considera a sequência como um conjunto de símbolos e utiliza funções de similaridade baseadas em conjuntos, como \textit{Jaccard}, \textit{Dice} e \textit{Cosseno}, como uma sequência de caracteres e utiliza a distância de edição como sua função de similaridade. Este trabalho concentra-se no \textit{SSJoin}.

Para responder eficientemente às associações de similaridade de \textit{strings}, a maioria dos trabalhos existentes segue uma estrutura de filtro e verificação \cite{Li:2008:EMF:1546682.1547171}, \cite{Wang:2012:WBP:2213836.2213847}, \cite{Rong:2013:6319300}, \cite{Li:2015:ESJ:2723372.2723733}. No estágio de filtro, os pares de \textit{strings} diferentes são removidos com base em alguns métodos de filtragem eficientes, por exemplo, utilizando filtro de prefixo, e assim os candidatos são gerados. Na fase de verificação, os candidatos são verificados calculando-se a pontuação de similaridade exata. Mais precisamente, o trabalho de Chaudhri et al. (2016)\cite{Chaudhuri:2006:POS:1129754.1129865} propôs o método de filtragem de prefixo utilizando \textit{tokens} de prefixo como assinaturas. A proposta feita por Xiao et al. (2008)\cite{Xiao:2008:ESJ:1367497.1367516} melhorou o filtro de prefixo, integrando a informação de posição e informação de comprimento. Bayardo et al. (2007) \cite{Bayardo:2007:SUP:1242572.1242591} construiu índices invertidos para todas as \textit{strings}, onde as chaves são \textit{tokens} das assinaturas e os valores são as \textit{strings} correspondentes contendo os \textit{tokens}. Li at al (2018)\cite{Li:2008:EMF:1546682.1547171}, Xiao et al. (2008)\cite{Xiao:2008:ESJ:1367497.1367516} propuseram outras técnicas de otimização para a lista invertida. No trabalho de Wang at al (2012)\cite{Wang:2012:WBP:2213836.2213847} estenderam a filtragem de prefixo baseada em comprimento fixo e propuseram uma filtragem de prefixo de tamanho variável. Para a mesma \textit{string}, Wang et al. (2012)\cite{Wang:2012:WBP:2213836.2213847} extrai mais \textit{tokens} do que os métodos de filtragem de prefixo baseados em comprimento fixo e constrói múltiplos índices invertidos de forma incremental. No trabalho de Wang at al (2012)\cite{Wang:2012:WBP:2213836.2213847} exploraram vários tipos de ordens globais e propuseram um algoritmo baseado em filtragem de múltiplos prefixos. Os vários filtros de prefixo são aplicados de forma incremental. No trabalho de Li at al (2015)\cite{Li:2015:ESJ:2723372.2723733} projetaram um índice baseado em árvore para prefixos de múltiplos atributos e propuseram um modelo de custo para guiar a construção do índice. Diferente desses estudos, neste trabalho focamos em como oferecer suporte a junções de similaridade em grande escala utilizando o \textit{Spark Apache}.

Para suportar junções de similaridade de strings em \textit{big data}, muitas contribuições recentes foram direcionadas à implementação de algoritmos em \textit{MapReduce} \cite{Vernica:2010:EPS:1807167.1807222}, \cite{Metwally:2012}, \cite{Deng:2014}. Mais precisamente, Vernica at al (2010) \cite{Vernica:2010:EPS:1807167.1807222} propôs um algoritmo baseado em assinatura, chamado \textit{RIDPairsPPJoin}, que segue a estrutura de filtro e verificação. Na fase de filtro, ele cria assinaturas para cada sequência, selecionando um conjunto de \textit{tokens} como prefixo, no qual os \textit{tokens} de uma \textit{string} são ordenados de acordo com uma ordem global pré-definida. Cada \textit{token} do prefixo é considerado como uma chave e uma \textit{string} com a chave inclusa é considerada como seu valor correspondente. As \textit{strings} com as mesmas assinaturas são transmitidas à um grupo para verificação adicional. Na fase de verificação, um índice invertido para cada grupo de \textit{strings} é criado para acelerar o processamento, e os métodos de filtragem são aplicados para podar ainda mais os pares dissimilares. No entanto, \textit{RIDPairsPPJoin} possui duas limitações: 
(1) uma sequência de strings pode ser duplicada várias vezes, uma vez que vários \textit{tokens} são selecionados como assinaturas, que incorrem em alto custo de ordenação e cálculos redundantes; e (2) os valores em cada \textit{job} do \textit{Reduce} são strings contendo a mesma chave, que possuem tamanhos diferentes. Portanto, não há garantia de balanceamento de carga nos nós \textit{Reduce}. Em Metwally et al. (2012)\cite{Metwally:2012} é relatado que \textit{RIPPJoin} não é escalável.

Em Metwally et al. (2012)\cite{Metwally:2012} propuseram um novo algoritmo \textit{V-Smart-Join} para junções por semelhança em \textit{multisets} e vetores. \textit{V-Smart-Join} por forma junções por similaridades em duas fases: \textbf{junção} e \textbf{similaridade}. Na fase de \textbf{junção}, ele contém vários \textit{jobs} e o \textit{MapReduce} fornece implementações diferentes, incluindo o \textit{Online-Aggregation}, pesquisa e distribuição. Na fase de \textbf{similaridade}, os resultados parciais são agregados para obter os pares de candidatos finais. De acordo com Metwally et al. (2012)\cite{Metwally:2012}, o \textit{Online-Aggregation} tem a melhor escalabilidade entre as três implementações. Na fase de junção, cada \textit{token} das strings é enviado como uma chave. Isto é como construir um índice invertido para todos os \textit{tokens} no conjunto de dados no \textit{HDFS}. \textit{V-Smart-Join} possui os mesmos problemas (duplicações e problemas de balanceamento de carga) como \textit{RIDPairsPPJoin}. Além disso, possui duas limitações extras: (1) o custo de enumerar cada par de corridas em cada lista invertida é dispendioso; e (2) nenhuma filtragem é aplicada durante o processo de junção, o que resulta em um alto número de falsos positivos, custo extra de ordenação e computação desnecessária.

Em Deng et al. (2014)\cite{Deng:2014} propuseram um método de junção de similaridade, chamado \textit{MassJoin}, para strings longas baseado em seu algoritmo centralizado por proposto em \cite{Li:2011}. No trabalho de Deng et al. (2014)\cite{Deng:2014}, cada \textit{string} \(s\) em \(S\) é particionada para segmentos pares e todos eles como suas assinaturas; para cada \textit{string} \(t\) em \(T\), ele deve gerar muitas assinaturas para assegurar que haja uma assinatura comum com $s$ que com comprimento em $\ceil{|t|*\theta} \leq |s| \leq \floor{|t|/\theta}$. Se $\theta = 0,8$ e $| t | = 100$, o intervalo de comprimento é $[80,125]$. Então, para cada inteiro de \(80\) à \(125\), a \textit{string} $t$ irá gerar assinaturas separadamente. Porém, possui ainda os mesmos problemas que o \textit{RIDPairsPPJoin}.

Para resolver os problemas de duplicação e balanceamento de carga, Rong et al. (2017)\cite{Rong:2017:FS-Join} propõe um novo \textit{framework} para junção por similaridade, chamado de \textit{FS-Join}. O \textit{FS-Join} aplica um método de particionamento vertical para particionar cada \textit{string} em segmentos disjuntos. Em que todos os segmentos em uma mesma partição constituem um fragmento. Os fragmentos possuem tamanhos iguais (ou similares). Na fase \textit{Map}, o \textit{FS-Join} utiliza os \textit{IDs} de partição como chaves e os segmentos correspondentes como valores. Como os segmentos são disjuntos, então, não há duplicações. Além disso, na fase \textit{Reduce}, todos os segmentos pertencentes ao mesmo fragmento são ordenados em um mesmo nó \textit{Reduce}. Como os fragmentos possuem os mesmos tamanhos, o \textit{FS-Join} garante um balanceamento de carga adequado. 
%A Tabela I resume a comparação de FS-Join e os métodos do estado da técnica, isto é, \textit{RIDPairsPPJoin} proposto por Vernica et al (2010)\cite{Vernica:2010:EPS:1807167.1807222}, \textit{V-Smart-Join} proposto por Metwally et al (2012)\cite{Metwally:2012} e \textit{MassJoin} proposto por Deng et al (2014)\cite{Deng:2014}, fornecida em Rong et al(2017)\cite{Rong:2017:FS-Join}.

Este trabalho propõe reproduzir o \textit{framework} \textit{FS-Join} proposto por \cite{Rong:2017:FS-Join}, aplicando todas as melhorias sugeridas. Respeitando as fases propostas, porém, utilizando como \textit{framework} para processamento paralelo e distribuído o \textit{Apache Spark} como substituto do utilizado por Rong et al. (2017)\cite{Rong:2017:FS-Join}.
